{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIKW1UBnGVHG"
      },
      "source": [
        "CELL 1: SETUP AND IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m267jR5OGbcG"
      },
      "outputs": [],
      "source": [
        "# --- Core Physics & Math Library ---\n",
        "import numpy as np  # Handles all vector states (spins), weight matrices, and linear algebra operations.\n",
        "\n",
        "# --- Data Visualization Libraries ---\n",
        "import matplotlib.pyplot as plt  # For plotting digit patterns and state trajectories.\n",
        "import seaborn as sns  # For generating statistical heatmaps and aesthetic plots.\n",
        "\n",
        "# --- Experiment Management ---\n",
        "import pandas as pd  # Stores simulation results (accuracy, entropy, noise levels) for analysis.\n",
        "from tqdm.notebook import tqdm  # Provides progress bars to track long-running simulations.\n",
        "\n",
        "# --- Dataset Loader ---\n",
        "import tensorflow as tf  # utilized SOLELY for downloading the MNIST dataset.\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_context(\"paper\", font_scale=1.4) # optimized for readability in papers\n",
        "\n",
        "print(\"Computational environment initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFacNuA9GgvQ"
      },
      "source": [
        "CELL 2: EXPERIMENT CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a14710nGlCW"
      },
      "outputs": [],
      "source": [
        "# This dictionary serves as the central control panel for the entire simulation.\n",
        "# It defines the physical constants, system dimensions, and experimental variables.\n",
        "\n",
        "CONFIG = {\n",
        "    # --- Physical System Dimensions ---\n",
        "    \"NUM_NEURONS\": 784,  # System Size (N). Corresponds to the 28x28 pixel grid of MNIST digits.\n",
        "    \"DIGITS_TO_STORE\": list(range(10)), # The set of Memory Patterns (xi^mu) available for storage.\n",
        "\n",
        "    # --- Network Topology Variants ---\n",
        "    # We compare two distinct network architectures:\n",
        "    # 1. Standard Hebbian (0.0): Fully symmetric weight matrix (Ising-like).\n",
        "    # 2. Biological (0.2): 20% of neurons are inhibitory, breaking symmetry (Dale's Principle).\n",
        "    \"INHIBITORY_FRACTIONS_TO_TEST\": [0.0, 0.2],\n",
        "\n",
        "    # --- Experiment 1: Phase Transition / Noise Robustness ---\n",
        "    # We sweep the noise level (Temperature equivalent) from 0% to 50% to observe the ferromagnetic-paramagnetic transition.\n",
        "    \"NOISE_LEVELS_EXP1\": np.linspace(0.0, 0.5, 11),\n",
        "\n",
        "    # --- Experiment 3: Storage Capacity ---\n",
        "    # We test the load parameter alpha = M/N by incrementally storing 1 to 10 patterns.\n",
        "    \"CAPACITY_TEST_PATTERNS_EXP3\": list(range(1, 11)),\n",
        "\n",
        "    # --- Statistical Controls ---\n",
        "    \"NUM_RUNS_PER_CONDITION\": 20, # Ensemble Size. We average over 20 independent trials to minimize statistical fluctuations.\n",
        "    \"MAX_RECALL_STEPS\": 1500,     # Time Limit. Sufficient for convergence to a fixed point or limit cycle.\n",
        "\n",
        "    # --- Analysis Metrics (Sample Entropy) ---\n",
        "    # These parameters tune the sensitivity of the complexity analysis for Experiment 2.\n",
        "    \"SAMPEN_M\": 2,          # Embedding Dimension: Length of sequences to compare.\n",
        "    \"SAMPEN_R_FRACTION\": 0.2 # Tolerance Threshold: 20% of the energy signal's standard deviation.\n",
        "}\n",
        "\n",
        "print(\"Experimental configuration loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WANCH0KsHIPR"
      },
      "source": [
        "CELL 3: CORE DEFINITIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW47upU0HZpZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# OPTIMIZED CORE: JIT-COMPILED DYNAMICS\n",
        "# ---------------------------------------------------------\n",
        "@jit(nopython=True)\n",
        "def _fast_recall_loop(current_state, weights, max_steps, record_energy):\n",
        "    \"\"\"\n",
        "    This function runs the physics simulation at C-speed.\n",
        "    It uses an incremental energy update (O(N)) instead of full recalculation (O(N^2)).\n",
        "    \"\"\"\n",
        "    N = len(current_state)\n",
        "    energy_history = np.zeros(max_steps)\n",
        "\n",
        "    # 1. Calculate Initial Energy (Expensive, but done only once)\n",
        "    # E = -0.5 * s.T * W * s\n",
        "    initial_field = weights.astype(np.float64) @ current_state.astype(np.float64)\n",
        "    current_energy = -0.5 * np.dot(current_state.astype(np.float64), initial_field)\n",
        "\n",
        "    # 2. The Loop\n",
        "    for step in range(max_steps):\n",
        "        # Pick random neuron\n",
        "        idx = np.random.randint(0, N)\n",
        "\n",
        "        # Calculate Local Field (h_i)\n",
        "        local_field = 0.0\n",
        "        for j in range(N):\n",
        "            local_field += weights[idx, j] * current_state[j]\n",
        "\n",
        "        # Update State\n",
        "        old_spin = current_state[idx]\n",
        "        new_spin = 1.0 if local_field >= 0 else -1.0\n",
        "\n",
        "        # 3. Only update energy if the spin actually flipped\n",
        "        if new_spin != old_spin:\n",
        "            current_state[idx] = new_spin\n",
        "\n",
        "            if record_energy:\n",
        "                # Delta E = -0.5 * Delta(s_i * sum_j w_ij s_j + s_i * sum_k w_ki s_k)\n",
        "                # For symmetric W: Delta E = - (new - old) * local_field\n",
        "                # For asymmetric W: We need column sum too.\n",
        "\n",
        "                # Calculate col_sum:\n",
        "                col_sum = 0.0\n",
        "                for k in range(N):\n",
        "                    col_sum += weights[k, idx] * current_state[k]\n",
        "\n",
        "                # The change in the quadratic term sWs\n",
        "                delta_s = new_spin - old_spin\n",
        "                delta_term = delta_s * (local_field + col_sum)\n",
        "\n",
        "                # E_new = E_old - 0.5 * delta_term\n",
        "                current_energy -= 0.5 * delta_term\n",
        "\n",
        "        if record_energy:\n",
        "            energy_history[step] = current_energy\n",
        "\n",
        "    return current_state, energy_history\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# WRAPPER CLASS\n",
        "# ---------------------------------------------------------\n",
        "class HopfieldNetwork:\n",
        "    \"\"\"\n",
        "    Optimized Wrapper for the Hopfield Network.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_neurons, inhibitory_fraction=0.0):\n",
        "        self.N = num_neurons\n",
        "        self.weights = np.zeros((num_neurons, num_neurons), dtype=np.float64)\n",
        "        self.inhibitory_neurons = []\n",
        "\n",
        "        if inhibitory_fraction > 0:\n",
        "            num_inhibitory = int(self.N * inhibitory_fraction)\n",
        "            self.inhibitory_neurons = np.random.choice(range(self.N), size=num_inhibitory, replace=False)\n",
        "\n",
        "    def train(self, patterns):\n",
        "        M = len(patterns)\n",
        "        if M == 0: return\n",
        "        # Standard Hebbian Rule\n",
        "        # Cast to float64 to ensure Numba compatibility\n",
        "        self.weights = np.sum([np.outer(p, p) for p in patterns], axis=0).astype(np.float64)\n",
        "        self.weights /= M\n",
        "        np.fill_diagonal(self.weights, 0)\n",
        "\n",
        "        # Apply Inhibition\n",
        "        if len(self.inhibitory_neurons) > 0:\n",
        "            self.weights[self.inhibitory_neurons, :] *= -1\n",
        "\n",
        "    def recall(self, initial_pattern, max_steps=100, record_energy=True):\n",
        "        # We cast inputs to ensure types match the JIT signature\n",
        "        state = initial_pattern.astype(np.float64).copy()\n",
        "\n",
        "        # Call the fast JIT function\n",
        "        final_state, history = _fast_recall_loop(\n",
        "            state,\n",
        "            self.weights,\n",
        "            int(max_steps),\n",
        "            record_energy\n",
        "        )\n",
        "\n",
        "        return final_state, history\n",
        "\n",
        "    def calculate_energy(self, state):\n",
        "        # Fallback for manual checks\n",
        "        return -0.5 * np.dot(state.T, np.dot(self.weights, state))\n",
        "\n",
        "# Keep the analysis functions unchanged\n",
        "def calculate_sampen(time_series, m=2, r_fraction=0.2):\n",
        "    N = len(time_series)\n",
        "    if N < m + 1: return 0\n",
        "    std_dev = np.std(time_series)\n",
        "    if std_dev == 0: return 0\n",
        "    r = r_fraction * std_dev\n",
        "    templates_m = np.array([time_series[i : i + m] for i in range(N - m)])\n",
        "    templates_m1 = np.array([time_series[i : i + m + 1] for i in range(N - m)])\n",
        "    B = np.sum(np.abs(templates_m[:, None] - templates_m) <= r) - len(templates_m)\n",
        "    A = np.sum(np.abs(templates_m1[:, None] - templates_m1) <= r) - len(templates_m1)\n",
        "    return -np.log(A / B) if A > 0 and B > 0 else 0\n",
        "\n",
        "def calculate_overlap(state1, state2):\n",
        "    return np.dot(state1, state2) / len(state1)\n",
        "\n",
        "def plot_digit(digit_vector, ax, title=\"\"):\n",
        "    ax.imshow(digit_vector.reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "print(\"Optimized Core Definitions ready (Numba Enabled).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK8Emk7wMwrm"
      },
      "source": [
        "CELL 4: LOADING AND PREPROCESSING THE MNIST DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO8mK_cKMyF8"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Loading and preparing the MNIST dataset ---\")\n",
        "# Use TensorFlow's Keras API to download the MNIST dataset.\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "# Binarize the images. Pixel values > 127 become +1, others become -1.\n",
        "# This maps the images to the (+1/-1) states of the neurons.\n",
        "x_train_binary = np.where(x_train.reshape((x_train.shape[0], -1)) > 127, 1, -1)\n",
        "\n",
        "# Select one prototype image for each digit we want to store in memory.\n",
        "digits_to_store = CONFIG[\"DIGITS_TO_STORE\"]\n",
        "# Find the index of the first occurrence of each digit.\n",
        "indices = [np.where(y_train == i)[0][0] for i in digits_to_store]\n",
        "# Create a dictionary mapping the digit label to its pattern vector.\n",
        "all_patterns = {digit: x_train_binary[index] for digit, index in zip(digits_to_store, indices)}\n",
        "\n",
        "print(f\"{len(all_patterns)} unique digit prototypes are ready for the experiments.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f5dbmxkNSG5"
      },
      "source": [
        "CELL 5: EXPERIMENT 1 & 2 - NOISE ROBUSTNESS AND DYNAMIC ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH1_wxWANTSD"
      },
      "outputs": [],
      "source": [
        "def run_noise_robustness_experiment(config, patterns_to_store):\n",
        "\n",
        "    \"\"\"A function to run the full noise robustness experiment.\"\"\"\n",
        "\n",
        "    all_results = []\n",
        "    patterns = list(patterns_to_store.values())\n",
        "\n",
        "    # Loop over the network types we want to test (Standard and Inhibitory).\n",
        "    for frac in config[\"INHIBITORY_FRACTIONS_TO_TEST\"]:\n",
        "        print(f\"\\n--- Running Robustness Experiment: Inhibitory Fraction = {frac} ---\")\n",
        "        net = HopfieldNetwork(config[\"NUM_NEURONS\"], inhibitory_fraction=frac)\n",
        "        net.train(patterns)\n",
        "\n",
        "        # Loop over the different noise levels defined in the CONFIG.\n",
        "        for noise in tqdm(config[\"NOISE_LEVELS_EXP1\"], desc=f\"Noise Levels (Inhibition={frac})\"):\n",
        "            # Repeat the experiment multiple times to get reliable statistics.\n",
        "            for _ in range(config[\"NUM_RUNS_PER_CONDITION\"]):\n",
        "                original_pattern = patterns[np.random.randint(len(patterns))]\n",
        "\n",
        "                # Create a corrupted input by flipping a fraction of the bits.\n",
        "                initial_pattern = original_pattern.copy()\n",
        "                num_to_flip = int(noise * config[\"NUM_NEURONS\"])\n",
        "                flip_indices = np.random.choice(range(config[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "                initial_pattern[flip_indices] *= -1\n",
        "\n",
        "                # Run the recall process and collect the key observables.\n",
        "                final_state, energy_history = net.recall(initial_pattern, max_steps=config[\"MAX_RECALL_STEPS\"])\n",
        "                accuracy = calculate_overlap(final_state, original_pattern)\n",
        "                entropy = calculate_sampen(energy_history, m=config[\"SAMPEN_M\"], r_fraction=config[\"SAMPEN_R_FRACTION\"])\n",
        "\n",
        "                # Store the results in a list of dictionaries.\n",
        "                all_results.append({\n",
        "                    'noise': noise,\n",
        "                    'accuracy': accuracy,\n",
        "                    'entropy': entropy,\n",
        "                    'inhibitory_fraction': frac\n",
        "                })\n",
        "    # Return the results as a Pandas DataFrame for easy analysis.\n",
        "    return pd.DataFrame(all_results)\n",
        "\n",
        "# For the robustness experiment, we store a subset of digits (4)\n",
        "# to ensure the task is challenging but not impossible.\n",
        "patterns_for_exp1 = {d: p for d, p in all_patterns.items() if d in [0, 1, 2, 8]}\n",
        "df_exp1_results = run_noise_robustness_experiment(CONFIG, patterns_for_exp1)\n",
        "print(\"\\nRobustness Experiment completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdI5DB6pO3c0"
      },
      "source": [
        "CELL 6: EXPERIMENT 3 - MEMORY CAPACITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFS37tX6O5Ml"
      },
      "outputs": [],
      "source": [
        "def run_capacity_experiment(config, all_patterns):\n",
        "    \"\"\"\n",
        "    A function to run the memory capacity experiment.\n",
        "    We test how recall accuracy degrades as we store more and more patterns.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "\n",
        "    for frac in config[\"INHIBITORY_FRACTIONS_TO_TEST\"]:\n",
        "        print(f\"\\n--- Running Capacity Experiment: Inhibitory Fraction = {frac} ---\")\n",
        "        # Loop over the number of patterns to store, from 1 to 10.\n",
        "        for num_patterns in tqdm(config[\"CAPACITY_TEST_PATTERNS_EXP3\"], desc=f\"Number of Patterns (Inhibition={frac})\"):\n",
        "\n",
        "            # Select the first 'num_patterns' digits.\n",
        "            current_patterns_to_store = [all_patterns[d] for d in range(num_patterns)]\n",
        "\n",
        "            net = HopfieldNetwork(config[\"NUM_NEURONS\"], inhibitory_fraction=frac)\n",
        "            net.train(current_patterns_to_store)\n",
        "\n",
        "            total_accuracy = 0\n",
        "            # Test the recall for each stored pattern to get an average accuracy.\n",
        "            for original_pattern in current_patterns_to_store:\n",
        "                # Test with a low, fixed noise level (e.g., 10%) to check if the memory is stable.\n",
        "                initial_pattern = original_pattern.copy()\n",
        "                num_to_flip = int(0.1 * config[\"NUM_NEURONS\"])\n",
        "                flip_indices = np.random.choice(range(config[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "                initial_pattern[flip_indices] *= -1\n",
        "\n",
        "                # We don't need the energy history here, so we can disable it to save time.\n",
        "                final_state, _ = net.recall(initial_pattern, max_steps=config[\"MAX_RECALL_STEPS\"], record_energy=False)\n",
        "                total_accuracy += calculate_overlap(final_state, original_pattern)\n",
        "\n",
        "            average_accuracy = total_accuracy / num_patterns\n",
        "\n",
        "            all_results.append({\n",
        "                'num_patterns': num_patterns,\n",
        "                'avg_accuracy': average_accuracy,\n",
        "                'inhibitory_fraction': frac\n",
        "            })\n",
        "    return pd.DataFrame(all_results)\n",
        "\n",
        "df_exp3_results = run_capacity_experiment(CONFIG, all_patterns)\n",
        "print(\"\\nMemory Capacity Experiment completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk7XaDbwP0JQ"
      },
      "source": [
        "CELL 7: PLOTTING FOR REPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxALAGHpP2og"
      },
      "outputs": [],
      "source": [
        "def generate_report_plots(df1, df3):\n",
        "    \"\"\" Generates plots from the experiment results DataFrame. \"\"\"\n",
        "\n",
        "    print(\"\\n--- Generating Report Plots ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "    # Map the numeric fraction to a readable label for the plot legend.\n",
        "    df1['Network Type'] = df1['inhibitory_fraction'].map({0.0: 'Standard', 0.2: 'Inhibitory (20%)'})\n",
        "    df3['Network Type'] = df3['inhibitory_fraction'].map({0.0: 'Standard', 0.2: 'Inhibitory (20%)'})\n",
        "\n",
        "    # --- Create a figure with 3 subplots for our 3 main results.\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(22, 6.5))\n",
        "    fig.suptitle('Comparative Analysis of the Hopfield Network: Standard vs. Inhibitory', fontsize=20)\n",
        "\n",
        "    # --- Plot 1: Accuracy vs. Noise (Experiment 1) ---\n",
        "    sns.lineplot(ax=axes[0], data=df1, x='noise', y='accuracy', hue='Network Type', errorbar='sd', palette='viridis', marker='o')\n",
        "    axes[0].set_title('Experiment 1: Robustness to Noise', fontsize=16)\n",
        "    axes[0].set_xlabel('Noise Level (Fraction of Flipped Bits)')\n",
        "    axes[0].set_ylabel('Recall Accuracy (Overlap)')\n",
        "    axes[0].legend(title='Network Type')\n",
        "    axes[0].set_ylim(-0.1, 1.1)\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # --- Plot 2: Phase Space of Dynamics (Entropy vs Accuracy) ---\n",
        "    # A scatter plot to show every single simulation.\n",
        "\n",
        "    sns.scatterplot(\n",
        "        ax=axes[1],\n",
        "        data=df1,\n",
        "        x='accuracy',\n",
        "        y='entropy',\n",
        "        hue='Network Type',\n",
        "        style='Network Type',\n",
        "        alpha=0.6,\n",
        "        palette='viridis'\n",
        "    )\n",
        "\n",
        "    axes[1].set_title('Phase Space: Accuracy vs. Complexity', fontsize=16)\n",
        "    axes[1].set_xlabel('Final Accuracy (Overlap)')\n",
        "    axes[1].set_ylabel('Trajectory Complexity (Sample Entropy)')\n",
        "\n",
        "    # Add a vertical line to show our \"Success\" threshold\n",
        "    axes[1].axvline(0.9, color='red', linestyle='--', alpha=0.5, label='Success Threshold')\n",
        "    axes[1].legend(title='Network Type')\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # --- Plot 3: Memory Capacity (Experiment 3) ---\n",
        "    sns.lineplot(ax=axes[2], data=df3, x='num_patterns', y='avg_accuracy', hue='Network Type', errorbar='sd', palette='viridis', marker='o')\n",
        "    axes[2].set_title('Experiment 3: Memory Capacity', fontsize=16)\n",
        "    axes[2].set_xlabel('Number of Stored Patterns')\n",
        "    axes[2].set_ylabel('Average Recall Accuracy')\n",
        "    axes[2].legend(title='Network Type')\n",
        "    axes[2].set_ylim(-0.1, 1.1)\n",
        "    # Ensure integer ticks on the x-axis.\n",
        "    if \"CAPACITY_TEST_PATTERNS_EXP3\" in CONFIG:\n",
        "        axes[2].set_xticks(CONFIG[\"CAPACITY_TEST_PATTERNS_EXP3\"])\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# Generate the final plots from the collected data.\n",
        "# This will now use the updated definition of success.\n",
        "generate_report_plots(df_exp1_results, df_exp3_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1sxiXR4ZMfm"
      },
      "source": [
        "CELL 8: STATE SPACE TRAJECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A3I2FPZZB0v"
      },
      "outputs": [],
      "source": [
        "# This cell creates a 2D projection of the energy landscape to visualize the\n",
        "# recall process. The axes represent the network's similarity (overlap)\n",
        "# to two distinct, stored memories.\n",
        "\n",
        "def run_and_plot_trajectory(ax, inhibitory_fraction, patterns_to_use, noise_level=0.4):\n",
        "    \"\"\"\n",
        "    A dedicated function to run a single recall and plot its trajectory in the state space.\n",
        "    - ax: The matplotlib axis object to plot on.\n",
        "    - inhibitory_fraction: The fraction of inhibitory neurons for the network.\n",
        "    - patterns_to_use: A dictionary containing the target patterns.\n",
        "    - noise_level: The amount of corruption for the initial input.\n",
        "    \"\"\"\n",
        "    # --- 1. Setup the specific experiment ---\n",
        "    # We will train the network on two visually similar digits, '3' and '8'.\n",
        "    pattern_A = patterns_to_use[3]\n",
        "    pattern_B = patterns_to_use[8]\n",
        "\n",
        "    # Create and train the network\n",
        "    net = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=inhibitory_fraction)\n",
        "    net.train([pattern_A, pattern_B])\n",
        "\n",
        "    # Create a noisy version of pattern_A (the digit '3') as our starting point\n",
        "    initial_state = pattern_A.copy()\n",
        "    num_to_flip = int(noise_level * CONFIG[\"NUM_NEURONS\"])\n",
        "    flip_indices = np.random.choice(range(CONFIG[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "    initial_state[flip_indices] *= -1\n",
        "\n",
        "    # --- 2. Perform recall and record the state history ---\n",
        "    state_history = [initial_state.copy()]\n",
        "    current_state = initial_state.copy()\n",
        "    for _ in range(CONFIG[\"MAX_RECALL_STEPS\"]):\n",
        "        neuron_to_update = np.random.randint(CONFIG[\"NUM_NEURONS\"])\n",
        "        local_field = np.dot(net.weights[neuron_to_update, :], current_state)\n",
        "        new_state_i = 1 if local_field >= 0 else -1\n",
        "        current_state[neuron_to_update] = new_state_i\n",
        "        state_history.append(current_state.copy())\n",
        "\n",
        "    # --- 3. Calculate overlap trajectory ---\n",
        "    # For each state in the history, calculate its overlap with our two target memories.\n",
        "    overlap_A_history = [calculate_overlap(s, pattern_A) for s in state_history]\n",
        "    overlap_B_history = [calculate_overlap(s, pattern_B) for s in state_history]\n",
        "\n",
        "    # --- 4. Plot the trajectory ---\n",
        "    # The x-axis is the overlap with '3', the y-axis is the overlap with '8'.\n",
        "    num_steps = len(overlap_A_history)\n",
        "    # Create a color gradient that changes over time (from blue to red)\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, num_steps))\n",
        "\n",
        "    # Plot the path as a series of connected, colored points\n",
        "    for i in range(num_steps - 1):\n",
        "        ax.plot(overlap_A_history[i:i+2], overlap_B_history[i:i+2], color=colors[i], lw=1.5)\n",
        "\n",
        "    # Mark the start and end points\n",
        "    ax.scatter(overlap_A_history[0], overlap_B_history[0], color='blue', s=100, zorder=10, label='Start (Noisy \\'3\\')')\n",
        "    ax.scatter(overlap_A_history[-1], overlap_B_history[-1], color='red', s=100, zorder=10, marker='X', label='End (Final State)')\n",
        "\n",
        "    # Mark the location of the \"perfect\" memories in this space\n",
        "    ax.plot(1, calculate_overlap(pattern_A, pattern_B), 'go', markersize=10, label='Perfect \\'3\\' Memory')\n",
        "    ax.plot(calculate_overlap(pattern_B, pattern_A), 1, 'yo', markersize=10, label='Perfect \\'8\\' Memory')\n",
        "\n",
        "    ax.set_title(f'Network Type: {\"Inhibitory\" if inhibitory_fraction > 0 else \"Standard\"}', fontsize=16)\n",
        "    ax.set_xlabel(\"Overlap with Digit '3'\", fontsize=12)\n",
        "    ax.set_ylabel(\"Overlap with Digit '8'\", fontsize=12)\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    ax.legend()\n",
        "    ax.set_xlim(0, 1.1)\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "\n",
        "# --- Main execution for this visualization ---\n",
        "# Create a figure with two subplots side-by-side to compare the two network types.\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "fig.suptitle('State Space Trajectory During Memory Recall', fontsize=20)\n",
        "\n",
        "# Run the experiment and plot for the Standard Network\n",
        "run_and_plot_trajectory(axes[0], inhibitory_fraction=0.0, patterns_to_use=all_patterns)\n",
        "\n",
        "# Run the experiment and plot for the Inhibitory Network\n",
        "run_and_plot_trajectory(axes[1], inhibitory_fraction=0.2, patterns_to_use=all_patterns)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_roAQB8VxI"
      },
      "source": [
        "CELL 9: THE ANATOMY OF MEMORY (WEIGHT MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryvcp41Y8VW0"
      },
      "outputs": [],
      "source": [
        "# This cell trains two networks (one standard and one inhibitory) and visualizes\n",
        "# their synaptic weight matrix (W). This allows us to see the physical\n",
        "# structure where memories are stored and to observe the structural\n",
        "# impact of inhibition.\n",
        "\n",
        "def run_and_plot_weight_matrix(ax, inhibitory_fraction, patterns_to_use, title):\n",
        "    \"\"\"\n",
        "    A dedicated function to train a network and visualize its weight matrix.\n",
        "    - ax: The matplotlib axis object to plot on.\n",
        "    - inhibitory_fraction: The fraction of inhibitory neurons for the network.\n",
        "    - patterns_to_use: A dictionary containing the patterns to be memorized.\n",
        "    - title: The title for the subplot.\n",
        "    \"\"\"\n",
        "    # --- 1. Setup and Training of the Network ---\n",
        "    # We use a subset of patterns for training (e.g., the first 5 digits)\n",
        "    patterns = [patterns_to_use[d] for d in [0, 1, 2, 3, 4]]\n",
        "\n",
        "    net = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=inhibitory_fraction)\n",
        "    net.train(patterns)\n",
        "\n",
        "    # --- 2. Visualization of the Weight Matrix ---\n",
        "    # We use seaborn.heatmap for a clear visualization with a color bar.\n",
        "    # 'viridis' is a perceptually uniform colormap.\n",
        "    sns.heatmap(net.weights, ax=ax, cmap='viridis', cbar=True)\n",
        "\n",
        "    ax.set_title(title, fontsize=16)\n",
        "    # We remove the axis labels for a cleaner visualization,\n",
        "    # since 784 ticks would not be readable.\n",
        "    ax.set_xlabel(\"Neuron j\")\n",
        "    ax.set_ylabel(\"Neuron i\")\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "\n",
        "# --- Main Execution for this Cell ---\n",
        "# We create a figure with two subplots side-by-side to compare the two network types.\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "fig.suptitle('Visualization of the Synaptic Weight Matrix (W)', fontsize=20)\n",
        "\n",
        "# Run the experiment and plot for the Standard Network\n",
        "run_and_plot_weight_matrix(axes[0],\n",
        "                           inhibitory_fraction=0.0,\n",
        "                           patterns_to_use=all_patterns,\n",
        "                           title=\"Standard Network (Symmetric)\")\n",
        "\n",
        "# Run the experiment and plot for the Inhibitory Network\n",
        "run_and_plot_weight_matrix(axes[1],\n",
        "                           inhibitory_fraction=0.2,\n",
        "                           patterns_to_use=all_patterns,\n",
        "                           title=\"Inhibitory Network (Asymmetric)\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXU1jIIU8zQ8"
      },
      "source": [
        "CELL 10: ANIMATED RECALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXZYVMzX8xYT"
      },
      "outputs": [],
      "source": [
        "# This cell creates an animation (GIF) of the recall process, showing the\n",
        "# network state (the digit image) evolving over time. It provides a dynamic\n",
        "# view of the \"error correction\" process.\n",
        "\n",
        "# We need a couple of extra imports for creating and displaying the animation\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "\n",
        "def run_and_generate_animation(inhibitory_fraction, patterns_to_use, digit_to_test=8, noise_level=0.2, animation_steps=800):\n",
        "    \"\"\"\n",
        "    A dedicated function to run a single recall and generate an animation of the process.\n",
        "    - inhibitory_fraction: The fraction of inhibitory neurons.\n",
        "    - patterns_to_use: A dictionary of the patterns to be stored.\n",
        "    - digit_to_test: The digit we will corrupt and try to recall.\n",
        "    - noise_level: The amount of corruption for the initial input.\n",
        "    - animation_steps: The number of update steps to record for the animation.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Generating Animation (Network: {'Inhibitory' if inhibitory_fraction > 0 else 'Standard'}) ---\")\n",
        "\n",
        "    # --- 1. Setup the network and initial state ---\n",
        "    # We store a few patterns for the test.\n",
        "    patterns = [patterns_to_use[d] for d in [0, 1, 3, 5, 8]]\n",
        "    net = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=inhibitory_fraction)\n",
        "    net.train(patterns)\n",
        "\n",
        "    original_pattern = patterns_to_use[digit_to_test]\n",
        "\n",
        "    # Create a noisy version of the pattern\n",
        "    noisy_pattern = original_pattern.copy()\n",
        "    np.random.seed(43) # Use a fixed seed for reproducible noise\n",
        "    num_to_flip = int(noise_level * CONFIG[\"NUM_NEURONS\"])\n",
        "    flip_indices = np.random.choice(range(CONFIG[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "    noisy_pattern[flip_indices] *= -1\n",
        "\n",
        "    # --- 2. Perform recall and record the state history ---\n",
        "    # We run a custom loop to store the full state vector at each step.\n",
        "    state_history = [noisy_pattern.copy()]\n",
        "    current_state = noisy_pattern.copy()\n",
        "    for _ in range(animation_steps):\n",
        "        neuron_to_update = np.random.randint(CONFIG[\"NUM_NEURONS\"])\n",
        "        local_field = np.dot(net.weights[neuron_to_update, :], current_state)\n",
        "        new_state_i = 1 if local_field >= 0 else -1\n",
        "        current_state[neuron_to_update] = new_state_i\n",
        "        # Store the state every few steps to make the animation smoother and faster to generate\n",
        "        if _ % 5 == 0:\n",
        "             state_history.append(current_state.copy())\n",
        "\n",
        "    # --- 3. Create the animation ---\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    plt.close() # Prevent the static plot from showing up\n",
        "\n",
        "    # This function will be called for each frame of the animation\n",
        "    def animate(i):\n",
        "        ax.clear()\n",
        "        plot_digit(state_history[i], ax, title=f\"Recall Step: {i*5}\")\n",
        "\n",
        "    # Create the animation object.\n",
        "    # interval=50 means 50 milliseconds between frames.\n",
        "    anim = FuncAnimation(fig, animate, frames=len(state_history), interval=50, blit=False)\n",
        "\n",
        "    # To display the animation in Colab, we convert it to an HTML5 video.\n",
        "    return HTML(anim.to_html5_video())\n",
        "\n",
        "# --- Main execution for this cell ---\n",
        "# Generate and display the animation for the standard network.\n",
        "animation_standard = run_and_generate_animation(0.0, all_patterns)\n",
        "print(\"Standard Network Animation Ready.\")\n",
        "\n",
        "# Generate and display the animation for the inhibitory network.\n",
        "animation_inhibitory = run_and_generate_animation(0.2, all_patterns)\n",
        "print(\"Inhibitory Network Animation Ready.\")\n",
        "\n",
        "# Display the animations\n",
        "print(\"\\n--- Recall Animation for Standard Network ---\")\n",
        "display(animation_standard)\n",
        "\n",
        "print(\"\\n--- Recall Animation for Inhibitory Network ---\")\n",
        "display(animation_inhibitory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVo1fzhLR7Hr"
      },
      "source": [
        "CELL 11: DEMONSTRATION OF THE FULL RECALL PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jiq6zlYkSBSx"
      },
      "outputs": [],
      "source": [
        "# This cell creates a complete visual narrative: it shows an original memory\n",
        "# pattern, its corrupted version, and the final pattern reconstructed by the\n",
        "# Hopfield network.\n",
        "\n",
        "# --- Parameters for this specific visualization ---\n",
        "DIGIT_TO_SHOW = 5  # The digit we want to use for the demonstration.\n",
        "NOISE_LEVEL_DEMO = 0.35  # The fraction of noise to apply (35%).\n",
        "# We will train on a few digits to make the recall task non-trivial.\n",
        "PATTERNS_TO_TRAIN_ON = [0, 1, 3, 5, 8]\n",
        "\n",
        "print(f\"Creating full recall visualization for digit '{DIGIT_TO_SHOW}' with {int(NOISE_LEVEL_DEMO*100)}% noise.\")\n",
        "\n",
        "# --- 1. Data and Network Preparation ---\n",
        "# Retrieve the original pattern from our 'all_patterns' dictionary.\n",
        "original_pattern_demo = all_patterns[DIGIT_TO_SHOW]\n",
        "\n",
        "# Create a noisy version of the pattern.\n",
        "noisy_pattern_demo = original_pattern_demo.copy()\n",
        "num_to_flip_demo = int(NOISE_LEVEL_DEMO * CONFIG[\"NUM_NEURONS\"])\n",
        "np.random.seed(101) # Use a fixed seed for reproducible noise.\n",
        "flip_indices_demo = np.random.choice(range(CONFIG[\"NUM_NEURONS\"]), size=num_to_flip_demo, replace=False)\n",
        "noisy_pattern_demo[flip_indices_demo] *= -1\n",
        "\n",
        "# --- 2. Run the Recall Process ---\n",
        "# Create and train a standard Hopfield network for this demonstration.\n",
        "patterns_for_training = [all_patterns[d] for d in PATTERNS_TO_TRAIN_ON]\n",
        "net_demo = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=0.0)\n",
        "net_demo.train(patterns_for_training)\n",
        "\n",
        "# Run the recall process on the noisy input.\n",
        "recalled_state_demo, _ = net_demo.recall(noisy_pattern_demo, max_steps=CONFIG[\"MAX_RECALL_STEPS\"], record_energy=False)\n",
        "final_overlap_demo = calculate_overlap(recalled_state_demo, original_pattern_demo)\n",
        "print(f\"Final overlap with original pattern: {final_overlap_demo:.3f}\")\n",
        "\n",
        "\n",
        "# --- 3. Plot Creation ---\n",
        "# We create a figure with three subplots to show the full story.\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "fig.suptitle('Visual Demonstration of Associative Memory Recall', fontsize=16)\n",
        "\n",
        "# Panel 1\n",
        "plot_digit(original_pattern_demo, axes[0], title=f\"Original Pattern ('{DIGIT_TO_SHOW}')\")\n",
        "\n",
        "# Panel 2\n",
        "plot_digit(noisy_pattern_demo, axes[1], title=f\"Corrupted Input ({int(NOISE_LEVEL_DEMO*100)}% Noise)\")\n",
        "\n",
        "# Panel 3\n",
        "plot_digit(recalled_state_demo, axes[2], title=\"Reconstructed Pattern\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}