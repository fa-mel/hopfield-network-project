{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIKW1UBnGVHG"
      },
      "source": [
        "CELL 1: SETUP AND IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m267jR5OGbcG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- Core Physics & Math Library ---\n",
        "import numpy as np  # Handles all vector states (spins), weight matrices, and linear algebra operations.\n",
        "\n",
        "# --- Data Visualization Libraries ---\n",
        "import matplotlib.pyplot as plt  # For plotting digit patterns and state trajectories.\n",
        "import seaborn as sns  # For generating heatmaps and plots.\n",
        "\n",
        "# --- Experiment Management ---\n",
        "import pandas as pd  # Stores simulation results (accuracy, entropy, noise levels) for analysis.\n",
        "from tqdm.notebook import tqdm  # Provides progress bars to track long-running simulations.\n",
        "\n",
        "# --- Dataset Loader ---\n",
        "import tensorflow as tf  # utilized for downloading the MNIST dataset.\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_context(\"paper\", font_scale=1.4)\n",
        "\n",
        "print(\"Computational environment initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFacNuA9GgvQ"
      },
      "source": [
        "CELL 2: EXPERIMENT CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a14710nGlCW"
      },
      "outputs": [],
      "source": [
        "# Configuration dictionary centralizing all simulation parameters and physical constants.\n",
        "CONFIG = {\n",
        "    # System dimensionality (N), matching the 784 pixels of a 28x28 MNIST image.\n",
        "    \"NUM_NEURONS\": 784,\n",
        "\n",
        "    # List of digit classes (0-9) designated for memory pattern storage.\n",
        "    \"DIGITS_TO_STORE\": list(range(10)),\n",
        "\n",
        "    # Ratio of inhibitory neurons to be tested: 0.0 (symmetric) and 0.2 (asymmetric).\n",
        "    \"INHIBITORY_FRACTIONS_TO_TEST\": [0.0, 0.2],\n",
        "\n",
        "    # Noise range for robustness testing, simulating thermal fluctuations from 0% to 50%.\n",
        "    \"NOISE_LEVELS_EXP1\": np.linspace(0.0, 0.5, 11),\n",
        "\n",
        "    # Range of stored patterns (M) used to evaluate the network load parameter.\n",
        "    \"CAPACITY_TEST_PATTERNS_EXP3\": list(range(1, 11)),\n",
        "\n",
        "    # Number of independent trials per condition to ensure statistical significance.\n",
        "    \"NUM_RUNS_PER_CONDITION\": 20,\n",
        "\n",
        "    # Upper limit for asynchronous update iterations to ensure system relaxation.\n",
        "    \"MAX_RECALL_STEPS\": 1500,\n",
        "\n",
        "    # Length of subsequences compared during Sample Entropy (SampEn) calculation.\n",
        "    \"SAMPEN_M\": 2,\n",
        "\n",
        "    # Similarity threshold for SampEn, set to 20% of the energy signal's standard deviation.\n",
        "    \"SAMPEN_R_FRACTION\": 0.2\n",
        "}\n",
        "\n",
        "print(\"Experimental configuration loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WANCH0KsHIPR"
      },
      "source": [
        "CELL 3: CORE DEFINITIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW47upU0HZpZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# OPTIMIZED CORE: JIT-COMPILED DYNAMICS\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "@jit(nopython=True)\n",
        "def _fast_recall_loop(current_state, weights, max_steps, record_energy):\n",
        "    \"\"\"\n",
        "    Executes the asynchronous update loop optimized with Numba for high-speed computation.\n",
        "    Updates system energy incrementally (O(N)) to avoid redundant matrix operations.\n",
        "    \"\"\"\n",
        "    N = len(current_state)\n",
        "    energy_history = np.zeros(max_steps)\n",
        "\n",
        "    # Initial system energy calculation: E = -0.5 * S^T * W * S.\n",
        "    initial_field = weights.astype(np.float64) @ current_state.astype(np.float64)\n",
        "    current_energy = -0.5 * np.dot(current_state.astype(np.float64), initial_field)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        # Stochastic selection of a single neuron index.\n",
        "        idx = np.random.randint(0, N)\n",
        "\n",
        "        # Calculation of the local field h_i acting on the selected neuron.\n",
        "        local_field = 0.0\n",
        "        for j in range(N):\n",
        "            local_field += weights[idx, j] * current_state[j]\n",
        "\n",
        "        # Application of the activation function: s_i = sign(h_i).\n",
        "        old_spin = current_state[idx]\n",
        "        new_spin = 1.0 if local_field >= 0 else -1.0\n",
        "\n",
        "        # Update system state and energy only if a spin-flip occurs.\n",
        "        if new_spin != old_spin:\n",
        "            current_state[idx] = new_spin\n",
        "\n",
        "            if record_energy:\n",
        "                # Calculation of column sum to account for potential weight matrix asymmetry.\n",
        "                col_sum = 0.0\n",
        "                for k in range(N):\n",
        "                    col_sum += weights[k, idx] * current_state[k]\n",
        "\n",
        "                # Incremental energy update based on the spin-flip magnitude and total field influence.\n",
        "                delta_s = new_spin - old_spin\n",
        "                delta_term = delta_s * (local_field + col_sum)\n",
        "                current_energy -= 0.5 * delta_term\n",
        "\n",
        "        if record_energy:\n",
        "            energy_history[step] = current_energy\n",
        "\n",
        "    return current_state, energy_history\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# WRAPPER CLASS\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "class HopfieldNetwork:\n",
        "    \"\"\"\n",
        "    Main interface for network initialization, Hebbian training, and pattern retrieval.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_neurons, inhibitory_fraction=0.0):\n",
        "        # Initialization of the weight matrix and identification of inhibitory neurons.\n",
        "        self.N = num_neurons\n",
        "        self.weights = np.zeros((num_neurons, num_neurons), dtype=np.float64)\n",
        "        self.inhibitory_neurons = []\n",
        "\n",
        "        if inhibitory_fraction > 0:\n",
        "            num_inhibitory = int(self.N * inhibitory_fraction)\n",
        "            self.inhibitory_neurons = np.random.choice(range(self.N), size=num_inhibitory, replace=False)\n",
        "\n",
        "    def train(self, patterns):\n",
        "        # Application of the Hebbian learning rule to store pattern prototypes.\n",
        "        M = len(patterns)\n",
        "        if M == 0: return\n",
        "\n",
        "        # Computation of the weight matrix as the normalized sum of outer products.\n",
        "        self.weights = np.sum([np.outer(p, p) for p in patterns], axis=0).astype(np.float64)\n",
        "        self.weights /= M\n",
        "        np.fill_diagonal(self.weights, 0) # Zeroing self-connections to prevent trivial attractors.\n",
        "\n",
        "        # Enforcement of Dale's Principle by making selected neuron outputs purely inhibitory.\n",
        "        if len(self.inhibitory_neurons) > 0:\n",
        "            self.weights[self.inhibitory_neurons, :] *= -1\n",
        "\n",
        "    def recall(self, initial_pattern, max_steps=100, record_energy=True):\n",
        "        # Prepares initial state and invokes the optimized JIT recall loop.\n",
        "        state = initial_pattern.astype(np.float64).copy()\n",
        "        final_state, history = _fast_recall_loop(state, self.weights, int(max_steps), record_energy)\n",
        "        return final_state, history\n",
        "\n",
        "    def calculate_energy(self, state):\n",
        "        # Standard matrix-based energy calculation for verification purposes.\n",
        "        return -0.5 * np.dot(state.T, np.dot(self.weights, state))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ANALYSIS & VISUALIZATION UTILITIES\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def calculate_sampen(time_series, m=2, r_fraction=0.2):\n",
        "    \"\"\"\n",
        "    Calculates Sample Entropy using Chebyshev distance to quantify energy trajectory complexity.\n",
        "    Determines regularity by comparing matching template sequences of length m and m+1.\n",
        "    \"\"\"\n",
        "    N = len(time_series)\n",
        "    if N < m + 1: return 0\n",
        "    std_dev = np.std(time_series)\n",
        "    if std_dev == 0: return 0\n",
        "    r = r_fraction * std_dev\n",
        "\n",
        "    # Generation of template sequences for dimensionality comparison.\n",
        "    templates_m = np.array([time_series[i : i + m] for i in range(N - m)])\n",
        "    templates_m1 = np.array([time_series[i : i + m + 1] for i in range(N - m)])\n",
        "\n",
        "    # Counting matches within tolerance r for sequences of length m.\n",
        "    diff_m = np.abs(templates_m[:, None, :] - templates_m[None, :, :])\n",
        "    matches_m = np.all(diff_m <= r, axis=-1)\n",
        "    B = np.sum(matches_m) - len(templates_m) # Excludes self-matches.\n",
        "\n",
        "    # Counting matches within tolerance r for sequences of length m+1.\n",
        "    diff_m1 = np.abs(templates_m1[:, None, :] - templates_m1[None, :, :])\n",
        "    matches_m1 = np.all(diff_m1 <= r, axis=-1)\n",
        "    A = np.sum(matches_m1) - len(templates_m1)\n",
        "\n",
        "    # Entropy calculation as the negative log of the conditional probability A/B.\n",
        "    if A > 0 and B > 0:\n",
        "        return -np.log(A / B)\n",
        "    return 0\n",
        "\n",
        "def calculate_overlap(state1, state2):\n",
        "    # Measures normalized similarity (dot product) between two system states.\n",
        "    return np.dot(state1, state2) / len(state1)\n",
        "\n",
        "def plot_digit(digit_vector, ax, title=\"\"):\n",
        "    # Visualizes a flattened 784-element state vector as a 28x28 grayscale image.\n",
        "    ax.imshow(digit_vector.reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "print(\"Optimized Core Definitions ready (Numba Enabled).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK8Emk7wMwrm"
      },
      "source": [
        "CELL 4: LOADING AND PREPROCESSING THE MNIST DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO8mK_cKMyF8"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Loading and preparing the MNIST dataset ---\")\n",
        "\n",
        "# Retrieval of the MNIST dataset via TensorFlow's Keras API.\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Data preprocessing: flattening the 28x28 images into 784-element vectors\n",
        "# and binarizing intensity values (Mapping: >127 to +1, otherwise -1)\n",
        "# to align with the bipolar spin states of the Hopfield model.\n",
        "x_train_binary = np.where(x_train.reshape((x_train.shape[0], -1)) > 127, 1, -1)\n",
        "\n",
        "# Selection of specific digit classes for memory storage based on CONFIG parameters.\n",
        "digits_to_store = CONFIG[\"DIGITS_TO_STORE\"]\n",
        "\n",
        "# Identification of the first occurrence index for each target digit in the dataset.\n",
        "indices = [np.where(y_train == i)[0][0] for i in digits_to_store]\n",
        "\n",
        "# Mapping of digit labels to their corresponding binarized pattern vectors for memory initialization.\n",
        "all_patterns = {digit: x_train_binary[index] for digit, index in zip(digits_to_store, indices)}\n",
        "\n",
        "print(f\"{len(all_patterns)} unique digit prototypes are ready for the experiments.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f5dbmxkNSG5"
      },
      "source": [
        "CELL 5: EXPERIMENT 1 & 2 - NOISE ROBUSTNESS AND DYNAMIC ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH1_wxWANTSD"
      },
      "outputs": [],
      "source": [
        "def run_noise_robustness_experiment(config, patterns_to_store):\n",
        "    \"\"\"\n",
        "    Executes a comprehensive experiment to evaluate network stability against stochastic noise.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    patterns = list(patterns_to_store.values())\n",
        "\n",
        "    # Iteration over specified network architectures: symmetric and asymmetric.\n",
        "    for frac in config[\"INHIBITORY_FRACTIONS_TO_TEST\"]:\n",
        "        print(f\"\\n--- Running Robustness Experiment: Inhibitory Fraction = {frac} ---\")\n",
        "\n",
        "        # Initialization and Hebbian training of the network for the current topology variant.\n",
        "        net = HopfieldNetwork(config[\"NUM_NEURONS\"], inhibitory_fraction=frac)\n",
        "        net.train(patterns)\n",
        "\n",
        "        # Systematic sweep of noise levels (bit-flip probabilities) to identify phase transition thresholds.\n",
        "        for noise in tqdm(config[\"NOISE_LEVELS_EXP1\"], desc=f\"Noise Levels (Inhibition={frac})\"):\n",
        "\n",
        "            # Ensemble averaging loop to ensure statistical robustness and minimize stochastic bias.\n",
        "            for _ in range(config[\"NUM_RUNS_PER_CONDITION\"]):\n",
        "                # Selection of a random target pattern from the stored memory set.\n",
        "                original_pattern = patterns[np.random.randint(len(patterns))]\n",
        "\n",
        "                # Generation of a corrupted initial state by flipping a fraction of bits equivalent to the noise level.\n",
        "                initial_pattern = original_pattern.copy()\n",
        "                num_to_flip = int(noise * config[\"NUM_NEURONS\"])\n",
        "                flip_indices = np.random.choice(range(config[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "                initial_pattern[flip_indices] *= -1\n",
        "\n",
        "                # Execution of the asynchronous recall process to reach an attractor state.\n",
        "                final_state, energy_history = net.recall(initial_pattern, max_steps=config[\"MAX_RECALL_STEPS\"])\n",
        "\n",
        "                # Calculation of retrieval fidelity (final overlap) and dynamical trajectory complexity (SampEn).\n",
        "                accuracy = calculate_overlap(final_state, original_pattern)\n",
        "                entropy = calculate_sampen(energy_history, m=config[\"SAMPEN_M\"], r_fraction=config[\"SAMPEN_R_FRACTION\"])\n",
        "\n",
        "                # Archiving trial-specific data into a structured record.\n",
        "                all_results.append({\n",
        "                    'noise': noise,\n",
        "                    'accuracy': accuracy,\n",
        "                    'entropy': entropy,\n",
        "                    'inhibitory_fraction': frac\n",
        "                })\n",
        "\n",
        "    # Consolidation of experimental data into a Pandas DataFrame for statistical analysis.\n",
        "    return pd.DataFrame(all_results)\n",
        "\n",
        "# Selection of a four-digit subset (0, 1, 2, 8) to establish the initial load for the robustness analysis.\n",
        "patterns_for_exp1 = {d: p for d, p in all_patterns.items() if d in [0, 1, 2, 8]}\n",
        "df_exp1_results = run_noise_robustness_experiment(CONFIG, patterns_for_exp1)\n",
        "print(\"\\nRobustness Experiment completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdI5DB6pO3c0"
      },
      "source": [
        "CELL 6: EXPERIMENT 3 - MEMORY CAPACITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFS37tX6O5Ml"
      },
      "outputs": [],
      "source": [
        "def run_capacity_experiment(config, all_patterns):\n",
        "    \"\"\"\n",
        "    Evaluates the storage capacity limits of the network by measuring retrieval fidelity\n",
        "    as the number of stored patterns (memory load) increases.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "\n",
        "    # Iteration over network topology variants: Standard (0.0) and Inhibitory (0.2).\n",
        "    for frac in config[\"INHIBITORY_FRACTIONS_TO_TEST\"]:\n",
        "        print(f\"\\n--- Running Capacity Experiment: Inhibitory Fraction = {frac} ---\")\n",
        "\n",
        "        # Incremental sweep of the number of stored memory patterns from 1 to 10.\n",
        "        for num_patterns in tqdm(config[\"CAPACITY_TEST_PATTERNS_EXP3\"], desc=f\"Number of Patterns (Inhibition={frac})\"):\n",
        "\n",
        "            # Retrieval of the subset of digit patterns for the current storage load.\n",
        "            current_patterns_to_store = [all_patterns[d] for d in range(num_patterns)]\n",
        "\n",
        "            # Re-initialization and training of the network for each specific pattern count.\n",
        "            net = HopfieldNetwork(config[\"NUM_NEURONS\"], inhibitory_fraction=frac)\n",
        "            net.train(current_patterns_to_store)\n",
        "\n",
        "            total_accuracy = 0\n",
        "            # Evaluation of recall success for every individual stored pattern to calculate an average.\n",
        "            for original_pattern in current_patterns_to_store:\n",
        "                # Introduction of a fixed 10% noise level to probe the stability of the attractor basins.\n",
        "                initial_pattern = original_pattern.copy()\n",
        "                num_to_flip = int(0.1 * config[\"NUM_NEURONS\"])\n",
        "                flip_indices = np.random.choice(range(config[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "                initial_pattern[flip_indices] *= -1\n",
        "\n",
        "                # Execution of the recall process with energy recording disabled to optimize speed.\n",
        "                final_state, _ = net.recall(initial_pattern, max_steps=config[\"MAX_RECALL_STEPS\"], record_energy=False)\n",
        "                total_accuracy += calculate_overlap(final_state, original_pattern)\n",
        "\n",
        "            # Normalization of the cumulative accuracy by the number of patterns stored.\n",
        "            average_accuracy = total_accuracy / num_patterns\n",
        "\n",
        "            # Archiving of the mean retrieval fidelity for each load condition and architecture.\n",
        "            all_results.append({\n",
        "                'num_patterns': num_patterns,\n",
        "                'avg_accuracy': average_accuracy,\n",
        "                'inhibitory_fraction': frac\n",
        "            })\n",
        "\n",
        "    # Conversion of experimental metrics into a structured DataFrame for comparative analysis.\n",
        "    return pd.DataFrame(all_results)\n",
        "\n",
        "# Execution of the storage capacity experiment across all defined configurations.\n",
        "df_exp3_results = run_capacity_experiment(CONFIG, all_patterns)\n",
        "print(\"\\nMemory Capacity Experiment completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk7XaDbwP0JQ"
      },
      "source": [
        "CELL 7: PLOTTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxALAGHpP2og"
      },
      "outputs": [],
      "source": [
        "def generate_report_plots(df1, df3):\n",
        "    \"\"\"\n",
        "    Generates report visualizations including phase space and centroid analysis.\n",
        "    Filters anti-patterns to ensure physically consistent evaluation of recall dynamics.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Generating Individual Plots with Centroid Analysis ---\")\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "    # Mapping configuration labels to descriptive legend names for clarity.\n",
        "    df1['Network Type'] = df1['inhibitory_fraction'].map({0.0: 'Standard', 0.2: 'Inhibitory (20%)'})\n",
        "    df3['Network Type'] = df3['inhibitory_fraction'].map({0.0: 'Standard', 0.2: 'Inhibitory (20%)'})\n",
        "\n",
        "    # --- Plot 1: Accuracy vs. Noise (Experiment 1) ---\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    # Visualization of the paramagnetic transition as a function of stochastic noise.\n",
        "    sns.lineplot(data=df1, x='noise', y='accuracy', hue='Network Type', errorbar='sd', palette='viridis', marker='o')\n",
        "    plt.title('Experiment 1: Robustness to Noise', fontsize=16)\n",
        "    plt.xlabel('Noise Level (Fraction of Flipped Bits)', fontsize=14)\n",
        "    plt.ylabel('Recall Accuracy (Overlap)', fontsize=14)\n",
        "    plt.ylim(-1.1, 1.1) # Range preserved to display initial distribution before filtering.\n",
        "    plt.grid(True)\n",
        "    plt.savefig('noise_robustness_plot.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot 2: Phase Space and Centroid Analysis (Experiment 2) ---\n",
        "    # Filtering: exclusion of negative overlaps (anti-patterns) to isolate correct retrieval dynamics.\n",
        "    df1_filtered = df1[df1['accuracy'] > 0].copy()\n",
        "\n",
        "    # Calculation of centroids representing mean accuracy and entropy for each architecture.\n",
        "    centroids = df1_filtered.groupby('Network Type')[['accuracy', 'entropy']].mean().reset_index()\n",
        "\n",
        "    plt.figure(figsize=(11, 8))\n",
        "    # Distribution of filtered trials across the accuracy-entropy phase space.\n",
        "    sns.scatterplot(\n",
        "        data=df1_filtered,\n",
        "        x='accuracy',\n",
        "        y='entropy',\n",
        "        hue='Network Type',\n",
        "        style='Network Type',\n",
        "        alpha=0.4,\n",
        "        palette='viridis'\n",
        "    )\n",
        "\n",
        "    # Insertion of centroids as distinct 'X' markers for quantitative comparison.\n",
        "    for i, row in centroids.iterrows():\n",
        "        color = 'darkblue' if row['Network Type'] == 'Standard' else 'darkgreen'\n",
        "        plt.scatter(\n",
        "            row['accuracy'],\n",
        "            row['entropy'],\n",
        "            s=250,\n",
        "            color=color,\n",
        "            marker='X',\n",
        "            edgecolor='white',\n",
        "            linewidth=2,\n",
        "            label=f\"Centroid {row['Network Type']}\"\n",
        "        )\n",
        "        # Annotation of numerical coordinates for data transparency.\n",
        "        plt.text(\n",
        "            row['accuracy'],\n",
        "            row['entropy'] + 0.0001,\n",
        "            f\"({row['accuracy']:.3f}, {row['entropy']:.5f})\",\n",
        "            fontsize=10,\n",
        "            horizontalalignment='center',\n",
        "            color=color,\n",
        "            weight='bold'\n",
        "        )\n",
        "\n",
        "    plt.title('Phase Space: Trajectory Complexity with Centroid Analysis', fontsize=16)\n",
        "    plt.xlabel('Final Accuracy (Overlap > 0)', fontsize=14)\n",
        "    plt.ylabel('Trajectory Complexity (Sample Entropy)', fontsize=14)\n",
        "    plt.axvline(0.9, color='red', linestyle='--', alpha=0.5, label='Success Threshold')\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.grid(True)\n",
        "    plt.savefig('phase_space_complexity_centroids.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot 3: Memory Capacity (Experiment 3) ---\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    # Evaluation of catastrophic forgetting as a function of the storage load parameter alpha.\n",
        "    sns.lineplot(data=df3, x='num_patterns', y='avg_accuracy', hue='Network Type', errorbar='sd', palette='viridis', marker='o')\n",
        "    plt.title('Experiment 3: Memory Capacity', fontsize=16)\n",
        "    plt.xlabel('Number of Stored Patterns', fontsize=14)\n",
        "    plt.ylabel('Average Recall Accuracy', fontsize=14)\n",
        "    plt.ylim(-0.1, 1.1)\n",
        "    if \"CAPACITY_TEST_PATTERNS_EXP3\" in CONFIG:\n",
        "        plt.xticks(CONFIG[\"CAPACITY_TEST_PATTERNS_EXP3\"])\n",
        "    plt.grid(True)\n",
        "    plt.savefig('memory_capacity_plot.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Tabular output for quantitative centroid verification in the report.\n",
        "    print(\"\\nCentroid Values (Quantitative Analysis):\")\n",
        "    print(centroids)\n",
        "\n",
        "# Execution of visualization suite using collected experimental data.\n",
        "generate_report_plots(df_exp1_results, df_exp3_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1sxiXR4ZMfm"
      },
      "source": [
        "CELL 8: STATE SPACE TRAJECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A3I2FPZZB0v"
      },
      "outputs": [],
      "source": [
        "# Function to visualize the system's trajectory within a 2D projection of the energy landscape.\n",
        "# The state space is defined by the network's similarity (overlap) to two stored memory patterns.\n",
        "\n",
        "def run_and_plot_trajectory(ax, inhibitory_fraction, patterns_to_use, noise_level=0.4):\n",
        "    \"\"\"\n",
        "    Executes a single recall instance and plots the evolution of the state vector\n",
        "    relative to two competing attractors in the state space.\n",
        "    \"\"\"\n",
        "    # --- 1. Experimental Setup ---\n",
        "    # Selection of visually similar memory prototypes ('3' and '8') to create a challenging landscape.\n",
        "    pattern_A = patterns_to_use[3]\n",
        "    pattern_B = patterns_to_use[8]\n",
        "\n",
        "    # Initialization and training of the network variant (Standard or Inhibitory).\n",
        "    net = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=inhibitory_fraction)\n",
        "    net.train([pattern_A, pattern_B])\n",
        "\n",
        "    # Generation of a corrupted initial state from pattern '3' using a defined noise level.\n",
        "    initial_state = pattern_A.copy()\n",
        "    num_to_flip = int(noise_level * CONFIG[\"NUM_NEURONS\"])\n",
        "    flip_indices = np.random.choice(range(CONFIG[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "    initial_state[flip_indices] *= -1\n",
        "\n",
        "    # --- 2. Recall Dynamics and State Recording ---\n",
        "    # Tracking of the system state throughout the asynchronous update process.\n",
        "    state_history = [initial_state.copy()]\n",
        "    current_state = initial_state.copy()\n",
        "    for _ in range(CONFIG[\"MAX_RECALL_STEPS\"]):\n",
        "        # Stochastic neuron selection and state update based on the local field.\n",
        "        neuron_to_update = np.random.randint(CONFIG[\"NUM_NEURONS\"])\n",
        "        local_field = np.dot(net.weights[neuron_to_update, :], current_state)\n",
        "        new_state_i = 1 if local_field >= 0 else -1\n",
        "        current_state[neuron_to_update] = new_state_i\n",
        "        state_history.append(current_state.copy())\n",
        "\n",
        "    # --- 3. Trajectory Projection ---\n",
        "    # Translation of high-dimensional neural states into 2D coordinates via overlap calculation.\n",
        "    overlap_A_history = [calculate_overlap(s, pattern_A) for s in state_history]\n",
        "    overlap_B_history = [calculate_overlap(s, pattern_B) for s in state_history]\n",
        "\n",
        "    # --- 4. Plotting and Visualization ---\n",
        "    # Rendering of the temporal path using a viridis color gradient to indicate time progression.\n",
        "    num_steps = len(overlap_A_history)\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, num_steps))\n",
        "\n",
        "    # Plotting the sequential state transitions in the projected overlap space.\n",
        "    for i in range(num_steps - 1):\n",
        "        ax.plot(overlap_A_history[i:i+2], overlap_B_history[i:i+2], color=colors[i], lw=1.5)\n",
        "\n",
        "    # Labeling of start and end points to differentiate between noise and convergence.\n",
        "    ax.scatter(overlap_A_history[0], overlap_B_history[0], color='blue', s=100, zorder=10, label='Start (Noisy \\'3\\')')\n",
        "    ax.scatter(overlap_A_history[-1], overlap_B_history[-1], color='red', s=100, zorder=10, marker='X', label='End (Final State)')\n",
        "\n",
        "    # Visualization of the target memory coordinates within the phase portrait.\n",
        "    ax.plot(1, calculate_overlap(pattern_A, pattern_B), 'go', markersize=10, label='Perfect \\'3\\' Memory')\n",
        "    ax.plot(calculate_overlap(pattern_B, pattern_A), 1, 'yo', markersize=10, label='Perfect \\'8\\' Memory')\n",
        "\n",
        "    # Formatting of axes and grid for formal report presentation.\n",
        "    ax.set_title(f'Network Type: {\"Inhibitory\" if inhibitory_fraction > 0 else \"Standard\"}', fontsize=16)\n",
        "    ax.set_xlabel(\"Overlap with Digit '3'\", fontsize=12)\n",
        "    ax.set_ylabel(\"Overlap with Digit '8'\", fontsize=12)\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    ax.legend()\n",
        "    ax.set_xlim(0, 1.1)\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "\n",
        "# --- Main Visualization Routine ---\n",
        "# Side-by-side comparison of standard symmetric dynamics versus inhibitory non-equilibrium trajectories.\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "fig.suptitle('State Space Trajectory During Memory Recall', fontsize=20)\n",
        "\n",
        "# Execution for the standard Hebbian architecture.\n",
        "run_and_plot_trajectory(axes[0], inhibitory_fraction=0.0, patterns_to_use=all_patterns)\n",
        "\n",
        "# Execution for the biological inhibitory architecture.\n",
        "run_and_plot_trajectory(axes[1], inhibitory_fraction=0.2, patterns_to_use=all_patterns)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_roAQB8VxI"
      },
      "source": [
        "CELL 9: THE ANATOMY OF MEMORY (WEIGHT MATRIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryvcp41Y8VW0"
      },
      "outputs": [],
      "source": [
        "# Function to train the network and visualize the resulting synaptic connectivity structure.\n",
        "# This analysis provides a structural baseline to compare symmetric and asymmetric architectures.\n",
        "\n",
        "def run_and_plot_weight_matrix(ax, inhibitory_fraction, patterns_to_use, title):\n",
        "    \"\"\"\n",
        "    Executes network training and generates a heatmap of the synaptic weight matrix (W).\n",
        "    - ax: Matplotlib axis for rendering.\n",
        "    - inhibitory_fraction: Fraction of neurons designated as inhibitory (Dale's Principle).\n",
        "    - patterns_to_use: Dictionary containing training prototypes.\n",
        "    - title: Subplot identification label.\n",
        "    \"\"\"\n",
        "    # --- 1. Network Initialization and Training ---\n",
        "    # Selection of a five-digit pattern subset (0-4) for memory initialization.\n",
        "    patterns = [patterns_to_use[d] for d in [0, 1, 2, 3, 4]]\n",
        "\n",
        "    # Instantiation of the Hopfield network with the specified inhibitory ratio.\n",
        "    net = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=inhibitory_fraction)\n",
        "\n",
        "    # Application of the Hebbian learning rule to populate the weight matrix.\n",
        "    net.train(patterns)\n",
        "\n",
        "    # --- 2. Structural Visualization ---\n",
        "    # Generation of a heatmap using a perceptually uniform colormap to represent weight magnitudes.\n",
        "    # This reveals the physical distribution of stored memory correlations.\n",
        "    sns.heatmap(net.weights, ax=ax, cmap='viridis', cbar=True)\n",
        "\n",
        "    ax.set_title(title, fontsize=16)\n",
        "\n",
        "    # Suppression of individual neuron ticks (784 total) to maintain visual clarity.\n",
        "    ax.set_xlabel(\"Neuron j\")\n",
        "    ax.set_ylabel(\"Neuron i\")\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "\n",
        "# --- Main Visualization Routine ---\n",
        "# Comparative display of standard symmetric weights versus asymmetric inhibitory structures.\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "fig.suptitle('Visualization of the Synaptic Weight Matrix (W)', fontsize=20)\n",
        "\n",
        "\n",
        "\n",
        "# Execution for the Standard Network, illustrating perfect symmetry across the diagonal (w_ij = w_ji).\n",
        "run_and_plot_weight_matrix(axes[0],\n",
        "                           inhibitory_fraction=0.0,\n",
        "                           patterns_to_use=all_patterns,\n",
        "                           title=\"Standard Network (Symmetric)\")\n",
        "\n",
        "# Execution for the Inhibitory Network, highlighting the \"striped\" pattern caused by unidirectional inhibitory columns.\n",
        "run_and_plot_weight_matrix(axes[1],\n",
        "                           inhibitory_fraction=0.2,\n",
        "                           patterns_to_use=all_patterns,\n",
        "                           title=\"Inhibitory Network (Asymmetric)\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXU1jIIU8zQ8"
      },
      "source": [
        "CELL 10: ANIMATED RECALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXZYVMzX8xYT"
      },
      "outputs": [],
      "source": [
        "# Imports required for the generation and browser-based rendering of dynamic neural simulations.\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "\n",
        "def run_and_generate_animation(inhibitory_fraction, patterns_to_use, digit_to_test=8, noise_level=0.2, animation_steps=800):\n",
        "    \"\"\"\n",
        "    Simulates the recall process and compiles the state evolution into a GIF animation for qualitative analysis.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Generating Animation (Network: {'Inhibitory' if inhibitory_fraction > 0 else 'Standard'}) ---\")\n",
        "\n",
        "    # Initialization of the network architecture and training using selected MNIST prototypes.\n",
        "    patterns = [patterns_to_use[d] for d in [0, 1, 3, 5, 8]]\n",
        "    net = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=inhibitory_fraction)\n",
        "    net.train(patterns)\n",
        "\n",
        "    original_pattern = patterns_to_use[digit_to_test]\n",
        "\n",
        "    # Application of bit-flip noise to the selected target pattern to test retrieval dynamics.\n",
        "    noisy_pattern = original_pattern.copy()\n",
        "    np.random.seed(43) # Fixed seed ensures consistency in initial state corruption across different runs.\n",
        "    num_to_flip = int(noise_level * CONFIG[\"NUM_NEURONS\"])\n",
        "    flip_indices = np.random.choice(range(CONFIG[\"NUM_NEURONS\"]), size=num_to_flip, replace=False)\n",
        "    noisy_pattern[flip_indices] *= -1\n",
        "\n",
        "    # Incremental recording of high-dimensional neural states during the asynchronous relaxation process.\n",
        "    state_history = [noisy_pattern.copy()]\n",
        "    current_state = noisy_pattern.copy()\n",
        "    for _ in range(animation_steps):\n",
        "        # Stochastic neuron selection and deterministic state update based on the local field sign.\n",
        "        neuron_to_update = np.random.randint(CONFIG[\"NUM_NEURONS\"])\n",
        "        local_field = np.dot(net.weights[neuron_to_update, :], current_state)\n",
        "        new_state_i = 1 if local_field >= 0 else -1\n",
        "        current_state[neuron_to_update] = new_state_i\n",
        "\n",
        "        # Sampling the system state at fixed intervals to optimize animation playback and generation speed.\n",
        "        if _ % 5 == 0:\n",
        "             state_history.append(current_state.copy())\n",
        "\n",
        "    # Implementation of the visual rendering logic for the animation sequence.\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    plt.close() # Suppression of static figure output to prevent redundant rendering.\n",
        "\n",
        "    def animate(i):\n",
        "        # Clears and redraws the 28x28 neural grid for the current time step i.\n",
        "        ax.clear()\n",
        "        plot_digit(state_history[i], ax, title=f\"Recall Step: {i*5}\")\n",
        "\n",
        "    # Aggregation of the recorded history into a temporal sequence for dynamic observation.\n",
        "    anim = FuncAnimation(fig, animate, frames=len(state_history), interval=50, blit=False)\n",
        "\n",
        "    # Conversion of the animation into HTML5 format for visual comparison of relaxation regimes.\n",
        "    return HTML(anim.to_html5_video())\n",
        "\n",
        "# --- Sequential execution of the animation routine for both network variants ---\n",
        "# Generation of the dynamic retrieval sequence for the standard Hebbian architecture.\n",
        "animation_standard = run_and_generate_animation(0.0, all_patterns)\n",
        "print(\"Standard Network Animation Ready.\")\n",
        "\n",
        "# Generation of the dynamic retrieval sequence for the inhibitory architecture.\n",
        "animation_inhibitory = run_and_generate_animation(0.2, all_patterns)\n",
        "print(\"Inhibitory Network Animation Ready.\")\n",
        "\n",
        "# Display of the comparative animations within the Jupyter environment.\n",
        "print(\"\\n--- Recall Animation for Standard Network ---\")\n",
        "display(animation_standard)\n",
        "\n",
        "print(\"\\n--- Recall Animation for Inhibitory Network ---\")\n",
        "display(animation_inhibitory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVo1fzhLR7Hr"
      },
      "source": [
        "CELL 11: DEMONSTRATION OF THE FULL RECALL PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jiq6zlYkSBSx"
      },
      "outputs": [],
      "source": [
        "# Parameters for memory retrieval demonstration.\n",
        "DIGIT_TO_SHOW = 5  # Specific MNIST prototype selected for visual reconstruction.\n",
        "NOISE_LEVEL_DEMO = 0.35  # Fraction of bits stochastically flipped to test recall robustness.\n",
        "# A set of five distinct digits is used for training to ensure a non-trivial energy landscape.\n",
        "PATTERNS_TO_TRAIN_ON = [0, 1, 3, 5, 8]\n",
        "\n",
        "print(f\"Creating full recall visualization for digit '{DIGIT_TO_SHOW}' with {int(NOISE_LEVEL_DEMO*100)}% noise.\")\n",
        "\n",
        "# --- 1. Data and Network Preparation ---\n",
        "# Retrieval of the uncorrupted binarized prototype from the dataset.\n",
        "original_pattern_demo = all_patterns[DIGIT_TO_SHOW]\n",
        "\n",
        "# Corrupted input generation via state-flipping of 35% of randomly selected neurons.\n",
        "noisy_pattern_demo = original_pattern_demo.copy()\n",
        "num_to_flip_demo = int(NOISE_LEVEL_DEMO * CONFIG[\"NUM_NEURONS\"])\n",
        "np.random.seed(101) # Seed is fixed to ensure a reproducible noise distribution.\n",
        "flip_indices_demo = np.random.choice(range(CONFIG[\"NUM_NEURONS\"]), size=num_to_flip_demo, replace=False)\n",
        "noisy_pattern_demo[flip_indices_demo] *= -1\n",
        "\n",
        "# --- 2. Recall Process Execution ---\n",
        "# Initialization and Hebbian training of a symmetric Hopfield network with 784 neurons.\n",
        "patterns_for_training = [all_patterns[d] for d in PATTERNS_TO_TRAIN_ON]\n",
        "net_demo = HopfieldNetwork(CONFIG[\"NUM_NEURONS\"], inhibitory_fraction=0.0)\n",
        "net_demo.train(patterns_for_training)\n",
        "\n",
        "# Execution of the asynchronous update rule to drive the noisy input toward a stored attractor.\n",
        "# Energy recording is disabled to maximize computational throughput during demonstration.\n",
        "recalled_state_demo, _ = net_demo.recall(noisy_pattern_demo, max_steps=CONFIG[\"MAX_RECALL_STEPS\"], record_energy=False)\n",
        "final_overlap_demo = calculate_overlap(recalled_state_demo, original_pattern_demo)\n",
        "print(f\"Final overlap with original pattern: {final_overlap_demo:.3f}\")\n",
        "\n",
        "# --- 3. Visualization Generation ---\n",
        "# Comparative layout illustrating the original prototype, corrupted input, and final reconstructed state.\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "fig.suptitle('Visual Demonstration of Associative Memory Recall', fontsize=16)\n",
        "\n",
        "# Sequential plotting of patterns to illustrate the denoising and pattern completion capabilities.\n",
        "plot_digit(original_pattern_demo, axes[0], title=f\"Original Pattern ('{DIGIT_TO_SHOW}')\")\n",
        "plot_digit(noisy_pattern_demo, axes[1], title=f\"Corrupted Input ({int(NOISE_LEVEL_DEMO*100)}% Noise)\")\n",
        "plot_digit(recalled_state_demo, axes[2], title=\"Reconstructed Pattern\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}